name: CD

concurrency:
  group: production
  cancel-in-progress: true

on:
  workflow_dispatch:
    inputs:
      image_tag:
        required: true
        type: string

  workflow_call:
    inputs:
      image_tag:
        required: true
        type: string
env:
  # AZURE_CONTAINER_REGISTRY: "your-azure-container-registry"
  # CONTAINER_NAME: "your-container-name"
  RESOURCE_GROUP: "tsvi-rg"
  CLUSTER_NAME: "tsvi-aks"
  DEPLOYMENT_MANIFEST_PATH: "./deployments"

jobs:
  staging-end2end-tests:
    permissions:
      actions: read
      id-token: write # This is required for requesting the JWT
      contents: read  # This is required for actions/checkout
    
    runs-on: ubuntu-latest
    environment: STAGE
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Deploy to Kubernetes [STAGING ENVIRONMENT]
        run: |
          echo "kubectl apply -f deployments/"
      
      - name: UAT TESTS [STAGING ENVIRONMENT]
        run: |
          echo "running UAT tests with version tag: ${{ inputs.image_tag }}"

      - name: SMOKE TESTS [STAGING ENVIRONMENT]
        run: |
          echo "running SMOKE tests with version tag: ${{ inputs.image_tag }}"

      - name: PERFORMANCE TESTS [STAGING ENVIRONMENT]
        run: |
          echo "running PERFORMANCE tests with version tag: ${{ inputs.image_tag }}"
  
  production:
    permissions:
      actions: read
      id-token: write # This is required for requesting the JWT
      contents: read  # This is required for actions/checkout
    
    runs-on: ubuntu-latest
    environment: PROD
    needs: [staging-end2end-tests]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: 'Az CLI Login via OIDC'
        uses: azure/login@v1.4.6
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      
      # Use kubelogin to configure your kubeconfig for Azure auth
      - name: Set up kubelogin for non-interactive login
        uses: azure/use-kubelogin@v1
        with:
          kubelogin-version: 'v0.0.25'

      # Retrieves your Azure Kubernetes Service cluster's kubeconfig file
      - name: Get K8s context
        uses: azure/aks-set-context@v3
        with:
          resource-group: ${{ env.RESOURCE_GROUP }}
          cluster-name: ${{ env.CLUSTER_NAME }}
          admin: 'false'
          use-kubelogin: 'true'
      
      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh

      - name: Deploy to Kubernetes [PRODUCTION ENVIRONMENT]
        run: |
          # Get the commit message of the commit that triggered the workflow
          COMMIT_MESSAGE=$(git log --format=%B -n 1 HEAD)

          # Extract just the tagname from inputs.image_tag
          IMAGE_TAG=$(echo "${{ inputs.image_tag }}" | cut -d ":" -f 2)

          # Check if the app deployment exists
          if kubectl get deployments app-release-my-chart-v1 && kubectl get deployments app-release-my-chart-v2; then
            # Get the current v1 and v2 image tags from the app deployment in the cluster
            CURRENT_V1_IMAGE_TAG=$(kubectl get pods -l app=spring-app -o json | jq -r '.items[] | select(.metadata.name | contains("v1")) | .spec.containers[0].image' | cut -d ":" -f 2 | head -n 1)
            CURRENT_V2_IMAGE_TAG=$(kubectl get pods -l app=spring-app -o json | jq -r '.items[] | select(.metadata.name | contains("v2")) | .spec.containers[0].image' | cut -d ":" -f 2 | head -n 1)
            
            echo "Current v1 image tag: $CURRENT_V1_IMAGE_TAG"
            echo "Current v2 image tag: $CURRENT_V2_IMAGE_TAG"
            
            # If the commit message starts with [v1], it's an update for v1
            if [[ "$COMMIT_MESSAGE" == \[v1\]* ]]; then
              echo "Update is for v1. Not setting v2.image.tag."
              # Update the app without changing the v2 image but instead change the v1 image to IMAGE_TAG ensure the v2.image.tag is not changed from the values.yaml file
              helm upgrade --install app-release ./my-chart --set v1.springAppContainer.image.tag=$IMAGE_TAG,v2.springAppContainer.image.tag=$CURRENT_V2_IMAGE_TAG
            else
              # If the commit message does not start with [v1], it's an update for v2
              echo "Update is for v2. Setting v2.image.tag to: $IMAGE_TAG."
              # Update the app and change the v2 image to IMAGE_TAG
              helm upgrade --install app-release ./my-chart --set v2.springAppContainer.image.tag=$IMAGE_TAG,v1.springAppContainer.image.tag=$CURRENT_V1_IMAGE_TAG
            fi
          else
            # If the app deployment does not exist
            echo "App deployment does not exist. Setting v2.image.tag to: $IMAGE_TAG."
            # Set v2.image.tag to IMAGE_TAG as a new deployment starting point and leave v1.image.tag as the default value in the values.yaml file
            helm upgrade --install app-release ./my-chart --set v2.springAppContainer.image.tag=$IMAGE_TAG
          fi

          # Wait for 30 seconds
          sleep 30

          # Get the status of the deployments
          kubectl get deployments